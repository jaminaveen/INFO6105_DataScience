{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook contains:\n",
    "- Reading the datset from Northeastern university\n",
    "- Modelling for classification models\n",
    "- Calculation of Error metrices\n",
    "- Summarizing Models at the end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Python Packages\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import DataConversionWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../../Data/all_records_northeastern.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the column, Unnamed as it is not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre_score</th>\n",
       "      <th>gre_score_quant</th>\n",
       "      <th>gre_score_verbal</th>\n",
       "      <th>test_score_toefl</th>\n",
       "      <th>undergraduation_score</th>\n",
       "      <th>work_ex</th>\n",
       "      <th>papers_published</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>316</td>\n",
       "      <td>164</td>\n",
       "      <td>152</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316</td>\n",
       "      <td>164</td>\n",
       "      <td>152</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>160</td>\n",
       "      <td>156</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>317</td>\n",
       "      <td>168</td>\n",
       "      <td>149</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>317</td>\n",
       "      <td>161</td>\n",
       "      <td>156</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reject</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gre_score  gre_score_quant  gre_score_verbal  test_score_toefl  \\\n",
       "0        316              164               152              99.0   \n",
       "1        316              164               152              99.0   \n",
       "2        316              160               156             114.0   \n",
       "3        317              168               149             106.0   \n",
       "4        317              161               156             106.0   \n",
       "\n",
       "   undergraduation_score  work_ex  papers_published  status  \n",
       "0                   3.12       12                 0  reject  \n",
       "1                   3.12       12                 0  reject  \n",
       "2                   2.97        0                 0  reject  \n",
       "3                   2.83       15                 0  reject  \n",
       "4                   2.01        0                 0  reject  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of accept and reject in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reject    1079\n",
       "accept     574\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see from above stats, our data is baised so we need to resample the data, in order to balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "balanced_data=resample(dataset[dataset.status=='accept'],replace=True,n_samples=1000,random_state=123)\n",
    "balanced_data=balanced_data.append(dataset[dataset.status=='reject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reject    1079\n",
       "accept    1000\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset=balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre_score</th>\n",
       "      <th>gre_score_quant</th>\n",
       "      <th>gre_score_verbal</th>\n",
       "      <th>test_score_toefl</th>\n",
       "      <th>undergraduation_score</th>\n",
       "      <th>work_ex</th>\n",
       "      <th>papers_published</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>314</td>\n",
       "      <td>165</td>\n",
       "      <td>149</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>315</td>\n",
       "      <td>162</td>\n",
       "      <td>153</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>accept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gre_score  gre_score_quant  gre_score_verbal  test_score_toefl  \\\n",
       "1589        314              165               149             100.0   \n",
       "1444        315              162               153             100.0   \n",
       "\n",
       "      undergraduation_score  work_ex  papers_published  status  \n",
       "1589                    2.9        0                 2  accept  \n",
       "1444                    3.3       60                 0  accept  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see from above stats, our data is baised so we need to resample the data, in order to balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=encoded_dataset[['gre_score_quant','gre_score_verbal','test_score_toefl','undergraduation_score','work_ex','papers_published']].copy()\n",
    "Y=encoded_dataset[['status']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeltraining(model,X_train,X_test,Y_train,Y_test):\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train = sc.transform(X_train)\n",
    "    \n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    model.fit(X_train,Y_train)\n",
    "    predicted_labels_test=model.predict(X_test)\n",
    "    predicted_labels_train=model.predict(X_train)\n",
    "    accuracy_test=accuracy_score(Y_test,predicted_labels_test)\n",
    "    accuracy_train=accuracy_score(Y_train,predicted_labels_train)\n",
    "\n",
    "    return model,predicted_labels_test,predicted_labels_train,accuracy_test,accuracy_train,sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling Support vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SVC(kernel='linear')\n",
    "svclassifier,Y_Pred_Test,Y_Pred_Train,accuracyTest,accuracyTrain,sc=modeltraining(model,X_train,X_test,Y_train,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6658653846153846"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracyTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6644618159951894"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracyTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[137  62]\n",
      " [ 77 140]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,Y_Pred_Test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      accept       0.64      0.69      0.66       199\n",
      "      reject       0.69      0.65      0.67       217\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       416\n",
      "   macro avg       0.67      0.67      0.67       416\n",
      "weighted avg       0.67      0.67      0.67       416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,Y_Pred_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      accept       0.64      0.66      0.65       801\n",
      "      reject       0.68      0.66      0.67       862\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      1663\n",
      "   macro avg       0.66      0.66      0.66      1663\n",
      "weighted avg       0.66      0.66      0.66      1663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_train,Y_Pred_Train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-fd21598142ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0my_pred_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accept'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_proba\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, type)\u001b[0m\n\u001b[0;32m    110\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m                     \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattribute_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         \"\"\"\n\u001b[1;32m--> 609\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    610\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m             raise AttributeError(\"predict_proba is not available when \"\n\u001b[0m\u001b[0;32m    577\u001b[0m                                  \" probability=False\")\n\u001b[0;32m    578\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'c_svc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nu_svc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "y_pred_proba = svclassifier.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_test, y_pred_proba,pos_label='accept')\n",
    "auc = metrics.roc_auc_score(Y_test,y_pred_proba,)\n",
    "plt.plot(tpr,fpr,label=\"Test, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "y_pred_proba = svclassifier.predict_proba(X_train)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(Y_train, y_pred_proba,pos_label='accept')\n",
    "auc = metrics.roc_auc_score(Y_train, y_pred_proba)\n",
    "plt.plot(tpr,fpr,label=\"Train, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypertuning the parameters using grid search, using c, degree and class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "param_grid = {\"C\":[1],\n",
    "              \"degree\":[3,4,5],\n",
    "              \"class_weight\":['balanced']\n",
    "             }\n",
    "\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(svclassifier, param_grid, cv=5,return_train_score=True)\n",
    "svclassifier,Y_Pred_Test,Y_Pred_Train,accuracyTest,accuracyTrain,sc=modeltraining(grid_search,X_train,X_test,Y_train,Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of train data after grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6586538461538461"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracyTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of test data after grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6596512327119664"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracyTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best estimator after grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'class_weight': 'balanced', 'degree': 3}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_list = Y_test['status'].tolist()\n",
    "y_test_list_new = []\n",
    "for i in y_test_list:\n",
    "    if i == 'accept':\n",
    "        y_test_list_new.append(0)\n",
    "    elif i == 'reject':\n",
    "        y_test_list_new.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_list = Y_Pred_Test.tolist()\n",
    "y_test_list_new = []\n",
    "for i in y_pred_test_list:\n",
    "    if i == 'accept':\n",
    "        y_pred_test_list_new.append(0)\n",
    "    elif i == 'reject':\n",
    "        y_pred_test_list_new.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_list_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 100 artists>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(40,10))\n",
    "plt.bar(np.arange(0,100,1),y_pred_test_list_new[:100],y_test_list_new[:100])\n",
    "#plt.plot(np.arange(0,100,1),y_pred_test_list_new[:100],color ='r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score for Test and Train:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Model</th>\n",
    "    <th>Test Accuracy</th> \n",
    "    <th>Train Accuracy</th>\n",
    "    <th>Grid Search - Test Accuracy</th> \n",
    "    <th>Grid Search - Test Accuracy</th>\n",
    "    <th>Test F1 Score</th> \n",
    "    <th>Train F1 Score</th>\n",
    "    <th>Best Parameter</th>\n",
    "    <th>Interpretability</th>\n",
    "    <th>Reproducability</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Model-SupportVectorMachine</th>\n",
    "    <th>0.6658</th> \n",
    "    <th>0.6844</th>\n",
    "    <th>Grid Search Test - 0.6686</th> \n",
    "    <th>Grid Search Train - 0.6944</th>\n",
    "    <th>0.66 </th> \n",
    "    <th>0.65</th>\n",
    "    <th>{'C': 1, 'class_weight': 'balanced', 'degree': 3}</th>\n",
    "     <th>Yes</th>\n",
    "    <th>Non-reproducable</th>\n",
    "  </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
